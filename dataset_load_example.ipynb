{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128608\n",
      "The pain the pain of a broken heart The price Ill pay for loving you I loved you from the very start But Ill get over losing you I just cant seem to realize Youre leaving me today As burning teardrops fill my eyes I watch you walk away The pain the pain of a broken heart The price Ill pay for loving you I loved you from the very start But Ill get over losing you I lost my love I lost my home I just cant seem to win If I get over losing you Ill never love again 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from preprocessing.build_dataset import get_dataset_splits\n",
    "from preprocessing.build_dataset import LABELS\n",
    "from preprocessing.SongsDataset import SongsDataset\n",
    "from preprocessing.TokenizeTransformer import TokenizeTransformer\n",
    "from preprocessing.RemoveStopwordsTransform import RemoveStopwordsTransform\n",
    "from preprocessing.RemovePunctuationTransformer import RemovePunctuationTransformer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.tokenize import word_tokenize\n",
    "import time\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_dataset_splits(\"english_cleaned_lyrics.csv\", train_size_p=0.8, val_size_p=0.1)\n",
    "\n",
    "train_dataset = SongsDataset(\n",
    "\tX_train, \n",
    "\ty_train, \n",
    "\ttransform=transforms.Compose([RemovePunctuationTransformer()])\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "for i, (x, y) in enumerate(train_dataset):\n",
    "\tprint(x, y)\n",
    "\tbreak\n",
    "\n",
    "\t\n",
    "\n",
    "# for i, x, y in enumerate(train_dataset):\n",
    "# \t# print(x, y)\n",
    "# \t# break\n",
    "# \tprint(i + 1)\n",
    "# \tpass\n",
    "\n",
    "# BATCH_SIZE = 16\n",
    "# train_loader = DataLoader(\n",
    "# \ttrain_dataset,\n",
    "# \tbatch_size=BATCH_SIZE,\n",
    "# \tshuffle=True,\n",
    "# )\n",
    "\n",
    "# for X, y in train_loader:\n",
    "# \tbreak"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0016f17c62ec39091140539b1be657552610c85dadf688efe3fb42df4e682225"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
